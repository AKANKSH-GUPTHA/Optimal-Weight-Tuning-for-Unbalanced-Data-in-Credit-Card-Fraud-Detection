{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=\"Class\", data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V20       V21  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.251412 -0.018307   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.524980  0.247998   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  1.475829  0.213454   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.059616  0.214205   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.001396  0.232045   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.127434  0.265245   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        Amount  \n",
       "0       149.62  \n",
       "1         2.69  \n",
       "2       378.66  \n",
       "3       123.50  \n",
       "4        69.99  \n",
       "...        ...  \n",
       "284802    0.77  \n",
       "284803   24.79  \n",
       "284804   67.88  \n",
       "284805   10.00  \n",
       "284806  217.00  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Confusion Matrix for RF: \n",
      "[[85297    11]\n",
      " [   33   102]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "predictions = RF.predict(X_test)\n",
    "print(\"*Confusion Matrix for RF: \")\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Classification Matrix for RF: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85308\n",
      "           1       0.90      0.76      0.82       135\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.95      0.88      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*Classification Matrix for RF: \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.94850368081644\n"
     ]
    }
   ],
   "source": [
    "val1 = accuracy_score(y_test, predictions) *100\n",
    "print(val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.903\n",
      "Recall: 0.756\n",
      "F1 Score: 0.823\n",
      "MCC: 0.823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "rf_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "rf_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "rf_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "rf_mcc = f1_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 AUC score: 0.9240139433755507\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_proba = RF.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "rf_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(RF, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "predictions = DT.predict(X_test)\n",
    "print(\"*Confusion Matrix for DT: \")\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*Classification Matrix for DT: \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val2 = accuracy_score(y_test, predictions) *100\n",
    "print(val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "dt_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "dt_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "dt_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "dt_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = DT.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "dt_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(DT, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "predictions = LR.predict(X_test)\n",
    "print(\"*Confusion Matrix for LR: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"*Classification Matrix for LR: \")\n",
    "print(classification_report(y_test, predictions))\n",
    "val3 = accuracy_score(y_test, predictions) *100\n",
    "print(val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "lr_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "lr_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "lr_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "lr_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = LR.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "lr_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(LR, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "LGBM = LGBMClassifier()\n",
    "LGBM.fit(X_train, y_train)\n",
    "predictions = LGBM.predict(X_test)\n",
    "print(\"*Confusion Matrix for LGBM: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"*Classification Matrix for LGBM: \")\n",
    "print(classification_report(y_test, predictions))\n",
    "val5 = accuracy_score(y_test, predictions) *100\n",
    "print(val5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "lgb_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "lgb_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "lgb_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "lgb_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = LGBM.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "lgb_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(LGBM, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGb = XGBClassifier()\n",
    "XGb.fit(X_train, y_train)\n",
    "predictions = XGb.predict(X_test)\n",
    "print(\"*Confusion Matrix for XGb: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"*Classification Matrix for XGb: \")\n",
    "print(classification_report(y_test, predictions))\n",
    "val6 = accuracy_score(y_test, predictions) *100\n",
    "print(val6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "xgb_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "xgb_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "xgb_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "xgb_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = XGb.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "xgb_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(XGb, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "clf = CatBoostClassifier(\n",
    "    iterations=5, \n",
    "    learning_rate=0.1, \n",
    "    #loss_function='CrossEntropy'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"*Confusion Matrix for Cat: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"*Classification Matrix for Cat: \")\n",
    "print(classification_report(y_test, predictions))\n",
    "val7 = accuracy_score(y_test, predictions) *100\n",
    "print(val7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "cat_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "cat_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "cat_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "cat_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = clf.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "cat_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "clf1 = LGBMClassifier()\n",
    "clf2 = XGBClassifier()\n",
    "clf3 = CatBoostClassifier()\n",
    "eclf1 = VotingClassifier(estimators=[('LG', clf1), ('XG', clf2), ('CAT', clf3)], voting='soft')\n",
    "eclf1.fit(X_train, y_train)\n",
    "predictions = eclf1.predict(X_test)\n",
    "print(\"*Confusion Matrix for Voting Classifier: \")\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*Classification Matrix for Voting Classifier: \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val8 = accuracy_score(y_test, predictions) *100\n",
    "print(val8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "vot1_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "vot1_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "vot1_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "vot1_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = eclf1.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "vot1_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(eclf1, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LGBMClassifier()\n",
    "clf2 = XGBClassifier()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('LG', clf1), ('XG', clf2)], voting='soft')\n",
    "eclf1.fit(X_train, y_train)\n",
    "predictions = eclf1.predict(X_test)\n",
    "print(\"*Confusion Matrix for Voting Classifier: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"*Classification Matrix for Voting Classifier: \")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "val9 = accuracy_score(y_test, predictions) *100\n",
    "print(val9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "vot2_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "vot2_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "vot2_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "vot2_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = eclf1.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "vot2_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(eclf1, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LGBMClassifier()\n",
    "clf2 = CatBoostClassifier()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('LG', clf1), ('CAT', clf2)], voting='soft')\n",
    "eclf1.fit(X_train, y_train)\n",
    "predictions = eclf1.predict(X_test)\n",
    "print(\"*Confusion Matrix for Voting Classifier: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"*Classification Matrix for Voting Classifier: \")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "val10 = accuracy_score(y_test, predictions) *100\n",
    "print(val10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "vot3_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "vot3_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "vot3_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "vot3_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = eclf1.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "vot3_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(eclf1, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = XGBClassifier()\n",
    "clf2 = CatBoostClassifier()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('XG', clf1), ('CAT', clf2)], voting='soft')\n",
    "eclf1.fit(X_train, y_train)\n",
    "predictions = eclf1.predict(X_test)\n",
    "print(\"*Confusion Matrix for Voting Classifier: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"*Classification Matrix for Voting Classifier: \")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "val11 = accuracy_score(y_test, predictions) *100\n",
    "print(val11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "vot4_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "vot4_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "vot4_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "vot4_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = eclf1.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "vot4_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(eclf1, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf1 = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf1.fit(X_train, y_train)\n",
    "predictions = clf1.predict(X_test)\n",
    "print(\"*Confusion Matrix for ANN: \")\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*Classification Matrix for ANN: \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val12 = accuracy_score(y_test, predictions) *100\n",
    "print(val12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "mlp_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "mlp_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "mlp_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "mlp_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = clf1.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "mlp_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(clf1, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)),('sgd',SGDClassifier(max_iter=1000, tol=1e-3))]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"*Confusion Matrix for Stack: \")\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*Classification Matrix for Stacking: \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val13 = accuracy_score(y_test, predictions) *100\n",
    "print(val13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
    "sta_prec = precision_score(y_test, predictions)\n",
    "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
    "sta_rec = recall_score(y_test, predictions)\n",
    "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
    "sta_f1 = f1_score(y_test, predictions)\n",
    "print('MCC: %.3f' % f1_score(y_test, predictions))\n",
    "sta_mcc = f1_score(y_test, predictions)\n",
    "\n",
    "y_proba = clf1.predict_proba(X_test)[:,1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "sta_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'model 1 AUC score: {roc_auc_score(y_test, y_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [val1,val2,val3,val5,val6,val7,val8,val9,val10,val11,val12,val13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = [rf_prec,dt_prec,lr_prec,lgb_prec,xgb_prec,cat_prec,vot1_prec,vot2_prec,vot3_prec,vot4_prec,mlp_prec,sta_prec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = [rf_rec,dt_rec,lr_rec,lgb_rec,xgb_rec,cat_rec,vot1_rec,vot2_rec,vot3_rec,vot4_rec,mlp_rec,sta_rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score3 = [rf_f1,dt_f1,lr_f1,lgb_f1,xgb_f1,cat_f1,vot1_f1,vot2_f1,vot3_f1,vot4_f1,mlp_f1,sta_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score4 = [rf_mcc,dt_mcc,lr_mcc,lgb_mcc,xgb_mcc,cat_mcc,vot1_mcc,vot2_mcc,vot3_mcc,vot4_mcc,mlp_mcc,sta_mcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score5 = [rf_auc,dt_auc,lr_auc,lgb_auc,xgb_auc,cat_auc,vot1_auc,vot2_auc,vot3_auc,vot4_auc,mlp_auc,sta_auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make variabel for save the result and to show it\n",
    "classifier = ('RF','DT','LR','LGBM','XGB','CAT','VOT - LG + XG + CAT','VOT - LG + XG','VOT - LG + CAT','VOT - CAT + XG','ANN','Stacking Classifier')\n",
    "y_pos = np.arange(len(classifier))\n",
    "print(y_pos)\n",
    "print(score)\n",
    "print(score1)\n",
    "print(score2)\n",
    "print(score3)\n",
    "print(score4)\n",
    "print(score5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "plt2.barh(y_pos, score, align='center', alpha=0.5,color='blue')\n",
    "plt2.yticks(y_pos, classifier)\n",
    "plt2.xlabel('Score')\n",
    "plt2.title('Classification Performance')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2.barh(y_pos, score1, align='center', alpha=0.5,color='red')\n",
    "plt2.yticks(y_pos, classifier)\n",
    "plt2.xlabel('Score')\n",
    "plt2.title('Classification Performance')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2.barh(y_pos, score2, align='center', alpha=0.5,color='green')\n",
    "plt2.yticks(y_pos, classifier)\n",
    "plt2.xlabel('Score')\n",
    "plt2.title('Classification Performance')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2.barh(y_pos, score3, align='center', alpha=0.5,color='orange')\n",
    "plt2.yticks(y_pos, classifier)\n",
    "plt2.xlabel('Score')\n",
    "plt2.title('Classification Performance')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2.barh(y_pos, score4, align='center', alpha=0.5,color='pink')\n",
    "plt2.yticks(y_pos, classifier)\n",
    "plt2.xlabel('Score')\n",
    "plt2.title('Classification Performance')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2.barh(y_pos, score5, align='center', alpha=0.5,color='violet')\n",
    "plt2.yticks(y_pos, classifier)\n",
    "plt2.xlabel('Score')\n",
    "plt2.title('Classification Performance')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_rf.sav'\n",
    "joblib.dump(RF, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
